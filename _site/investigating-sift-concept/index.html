<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no"> <title>Investigating SIFT concepts &#8211; Hand Map</title> <meta name="description" content="Looking at Scale-invariant feature transform and whether it would be applicable"> <meta name="keywords" content="SIFT, OpenCV"> <!-- Twitter Cards --> <meta name="twitter:card" content="summary"> <meta name="twitter:image" content="halve.png"> <meta name="twitter:title" content="Investigating SIFT concepts"> <meta name="twitter:description" content="Looking at Scale-invariant feature transform and whether it would be applicable"> <meta name="twitter:site" content="@nathangloverAUS"> <meta name="twitter:creator" content="@nathangloverAUS"> <!-- Open Graph --> <meta property="og:locale" content="en_US"> <meta property="og:type" content="article"> <meta property="og:title" content="Investigating SIFT concepts"> <meta property="og:description" content="Looking at Scale-invariant feature transform and whether it would be applicable"> <meta property="og:url" content="https://handmap.github.io/investigating-sift-concept/"> <meta property="og:site_name" content="Hand Map"> <meta property="og:image" content="https://handmap.github.io/images/halve.png"> <link rel="canonical" href="https://handmap.github.io/investigating-sift-concept/"> <!-- Handheld --> <meta name="HandheldFriendly" content="True"> <meta name="MobileOptimized" content="320"> <meta name="viewport" content="width=device-width, initial-scale=1.0"> <!-- Feed --> <link type="application/atom+xml" rel="alternate" href="https://handmap.github.io/feed.xml" title="Hand Map" /> <!-- Favicons --> <link rel="shortcut icon" type="image/png" href="https://handmap.github.io/favicon.png" /> <link rel="shortcut icon" href="https://handmap.github.io/favicon.ico" /> <!-- CSS --> <link rel="stylesheet" type="text/css" href="https://handmap.github.io/assets/css/main.css"> <!-- Left Block Image for Posts --> <style type="text/css"> #posts.inner-post-page .block-left {background: linear-gradient(rgba(0, 0, 0, 0.5), rgba(0, 0, 0, 0.5)), url(https://handmap.github.io/images/unsplash-gallery-image-3.jpg) no-repeat;background-size: cover;} </style> <!-- Left Block Images for Home and Pages --> <style type="text/css"> #posts .block-left {background: linear-gradient(rgba(0, 0, 0, 0.5), rgba(0, 0, 0, 0.5)), url(https://handmap.github.io/images/unsplash-image-10.jpg) no-repeat;background-size: cover, cover;} .block-left {background: linear-gradient(rgba(44,45,51,0.9), rgba(44,45,51,0.9)), url(https://handmap.github.io/images/home.png) no-repeat;background-size: cover;} </style> </head> <body id="posts" class="inner-post-page"> <div class="block-left"> <div class="content"> <a href="https://handmap.github.io" class="logo"><img src="https://handmap.github.io/images/halve.png"></a> <div class="post-title-section"> <div class="section-line">Posts <em>/</em></div> <h1 class="section-title">Investigating SIFT concepts </h1> <ul class="tags"> <li><a href="https://handmap.github.io/tags#SIFT">SIFT</a></li> <li><a href="https://handmap.github.io/tags#OpenCV">OpenCV</a></li> </ul> <div class="section-line reverse"><a href="https://handmap.github.io/posts">Back to posts</a> <em>/</em></div> </div> </div> </div> <div class="block-right"> <div class="share-buttons"> <a href="https://twitter.com/intent/tweet?text=https://handmap.github.io/investigating-sift-concept/" class="btn btn_twitter" title="Share on Twitter"><i class="fa fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a> <a href="https://www.facebook.com/sharer/sharer.php?u=https://handmap.github.io/investigating-sift-concept/" class="btn btn_facebook" title="Share on Facebook"><i class="fa fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a> <a href="https://plus.google.com/share?url=https://handmap.github.io/investigating-sift-concept/" class="btn btn_google-plus" title="Share on Google Plus"><i class="fa fa-fw fa-google-plus" aria-hidden="true"></i><span> Google+</span></a> </div> <a href="../posts.html" title="posts" class="posts-menu-icon"></a> <a title="projects" class="projects-menu-icon"> <span></span> </a> <div class="inner-post content"> <div class="date-highlight">14 May 2017</div> <h2 id="introduction">Introduction</h2> <hr /> <p>After looking into the Curatio hand mapping solution, It was clear that some aspects of the implementation could be potentially useful to the development of HandMap. In particular it would seem that a Scale-invariant feature transform (SIFT) method was used to generate a mesh of points from the 32 cameras utilized in the design.</p> <h2 id="scale-invariant-feature-transform">Scale-invariant feature transform</h2> <hr /> <p>Scale-invariant feature transform or more commonly referred to as SIFT is a method for matching features across different images. These matches can be used to get scale, rotation, illumination and viewport location of an object of interest in a series of photographs or video frames.</p> <figure> <img src="https://handmap.github.io/images/posts/2017-05-14/curatio-demo.jpg" alt="Curatio Demo" /> <figcaption>Curatio Demo</figcaption> </figure> <p>This idea was most likely implemented in the Curatio, as it can use its many cameras to capture the same object from a number of sides to produce a mesh output used for generating a 3D replica of a hand (or object).</p> <h3 id="computational-overhead">Computational overhead</h3> <hr /> <p>Before implementing the SIFT method for HandMap it was important to understand what kinds of computational requirements are needed to generate the 3D mesh. Luckily there was a simple implementation with a GUI called VisualSFM that allows for simple SIFT structural calculations and visualizations.</p> <h4 id="preparing-visualsfm-for-use">Preparing VisualSFM for use</h4> <hr /> <p>Following the instructions outlined on the <a href="http://ccwu.me/vsfm/install.html">VisualSFM documentation page</a> the set up of the platform on Windows was simple enough.</p> <p>The CMVS-PMVS binaries for Windows also need to be included in the directory of the VisualSFM folder. These can be obtained from the <a href="https://github.com/pmoulon/CMVS-PMVS">CMVS-PMVS git repo</a>. The binaries for your system can just be dropped in the root directory.</p> <figure> <img src="https://handmap.github.io/images/posts/2017-05-14/visual-sfm-files.jpg" alt="VisualSFM Files" /> <figcaption>VisualSFM Files</figcaption> </figure> <h4 id="generating-source-images-for-sift">Generating source images for SIFT</h4> <hr /> <p>In order to test the SIFT method a number of images was required of an object to scan. The quality of the images used directly influences the ratio of how many images you’ll need to get a reasonably successful result. In order to test, a video was taken of my hand that encompassed a number of different angles.</p> <p>This video was then converted into 884 still frame images using the following code:</p> <div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">cv2</span>

<span class="n">vidcap</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="s">'in-video.mp4'</span><span class="p">)</span>
<span class="n">success</span><span class="p">,</span><span class="n">image</span> <span class="o">=</span> <span class="n">vidcap</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">success</span> <span class="o">=</span> <span class="bp">True</span>
<span class="k">while</span> <span class="n">success</span><span class="p">:</span>
    <span class="n">success</span><span class="p">,</span><span class="n">image</span> <span class="o">=</span> <span class="n">vidcap</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Read a new frame: '</span><span class="p">,</span> <span class="n">success</span><span class="p">)</span>
    <span class="n">cv2</span><span class="o">.</span><span class="n">imwrite</span><span class="p">(</span><span class="s">"images/frame</span><span class="si">%</span><span class="s">d.jpg"</span> <span class="o">%</span> <span class="n">count</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span> <span class="c"># save frame as JPEG file</span>
    <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
</code></pre></div> <p>Then using the VisualSFM software, the images were loaded into the preview pane by selecting <code class="highlighter-rouge">File -&gt; Open+MultiImages</code></p> <figure> <img src="https://handmap.github.io/images/posts/2017-05-14/hand-images-for-sift.png" alt="VisualSFM Raw Hand Images" /> <figcaption>VisualSFM Raw Hand Images</figcaption> </figure> <p>Next click the <code class="highlighter-rouge">Match the Images</code> button. It should be the four arrows pointing outward in the menu bar (item 2 in the following image). This process should run quickly. The run the Sparse reconstruction by pressing item 3 in the menu.</p> <figure> <img src="https://handmap.github.io/images/posts/2017-05-14/visual-sfm-toolbar.jpg" alt="VisualSFM Match Images" /> <figcaption>VisualSFM Match Images</figcaption> </figure> <p>Depending on the number of source images, this process could take a while. In the example here, the 884 source images took roughly 20 minutes to complete the initial map.</p> <figure> <img src="https://handmap.github.io/images/posts/2017-05-14/visual-sfm-initial-map.png" alt="VisualSFM Initial Map" /> <figcaption>VisualSFM Initial Map</figcaption> </figure> <p>Note that the coloured pyramids represent a calculated position and rotation of a viewport (where the photo was taken from relative to the object).</p> <p>The next step is to generate a dense map. This uses all the known points to generate a more detailed point cloud. This is done by clicking item 4 in the menu. This process will take a really long time with a large number of images, the example here took 80 minutes. Once the process completes, press the TAB key to toggle between the sparse and dense maps.</p> <figure> <img src="https://handmap.github.io/images/posts/2017-05-14/visual-sfm-dense-mesh.png" alt="VisualSFM Dense Map" /> <figcaption>VisualSFM Dense Map</figcaption> </figure> <h4 id="viewing-mesh-in-meshlab">Viewing mesh in meshlab</h4> <hr /> <p>Once the dense reconstruction has occurred on the input images, you will find that a number of extra files will now be accompanying the images in your source folder. These, along with a couple <code class="highlighter-rouge">cmvs-output.x.ply</code> files can be used with <code class="highlighter-rouge">meshlab</code> to work with the captured object in 3D space.</p> <p>Simply open the CMVS file in meshlab and you’ll be able to rotate and manipulate the object in 3D.</p> <figure> <img src="https://handmap.github.io/images/posts/2017-05-14/mesh-lab-output.png" alt="meshlab output" /> <figcaption>meshlab output</figcaption> </figure> <h2 id="sift-mesh-conclusion">SIFT mesh conclusion</h2> <hr /> <p>It became clear even after the inital 20 minute time frame to generate the sparse map that SIFT would not be an optimal solution for HandMap to implement. The reason why it works so well for Curatio is due to the static positioning of the cameras used to capture the object held between them. This static positioning saves a lot of calculation time when generating the maps and mesh as the system knows where it is in relation to its brother and sister cameras.</p> <p>I do think there is a possible use case for the SIFT method in this project, especially if we can justify offloading some of the mesh processing to a system separate to the users video and photo capturing device. It offers some capabilities of filling in gaps of information when the core system doesn’t function as expected.</p> <h2 id="references">References</h2> <hr /> <p>Curatio: A Low-Cost &amp; Dedicated 3D Hand Scanner - <a href="https://jamesdysonaward.org/projects/curatio-low-cost-dedicated-3d-hand-scanner/">https://jamesdysonaward.org/projects/curatio-low-cost-dedicated-3d-hand-scanner/</a></p> <p>SIFT: Theory and Practice - <a href="http://aishack.in/tutorials/sift-scale-invariant-feature-transform-introduction/">http://aishack.in/tutorials/sift-scale-invariant-feature-transform-introduction/</a></p> <p>VisualSFM : A Visual Structure from Motion System - <a href="http://ccwu.me/vsfm/">http://ccwu.me/vsfm/</a></p> <br> <a href="https://twitter.com/intent/tweet?text=https://handmap.github.io/investigating-sift-concept/" class="btn btn_twitter" title="Share on Twitter"><i class="fa fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a> <a href="https://www.facebook.com/sharer/sharer.php?u=https://handmap.github.io/investigating-sift-concept/" class="btn btn_facebook" title="Share on Facebook"><i class="fa fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a> <a href="https://plus.google.com/share?url=https://handmap.github.io/investigating-sift-concept/" class="btn btn_google-plus" title="Share on Google Plus"><i class="fa fa-fw fa-google-plus" aria-hidden="true"></i><span> Google+</span></a> <nav class="pagination"> <a href="https://handmap.github.io/video-5-implementation-and-testing/" class="pagination_pager" title="Video 5 - Implementation and Testing ">previous</a> <a href="#" class="pagination_pager disabled">next</a> </nav> </div> </div> <!-- JS --> <script src="https://handmap.github.io/assets/js/main.min.js"></script> <div class="overlay"> <ul class="projects-menu"> <li style="background:url(https://github.com/HandMap/HandMap.github.io/blob/master/images/project.jpg) center center no-repeat;"> <a href="https://handmap.github.io" class="inactive" target="_blank" rel="nofollow external"> <span> Hand Map Project <br><em>in progress</em> </span> </a> </li> </ul> </div> </body> </html>
