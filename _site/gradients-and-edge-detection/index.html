<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no"> <title>Gradients and Edge Detection &#8211; Hand Map</title> <meta name="description" content="Today I look at how I can begin detecting the fingers on my hand using gradient and edge detection techniques"> <meta name="keywords" content="opencv, edge detection, gradient"> <!-- Twitter Cards --> <meta name="twitter:card" content="summary"> <meta name="twitter:image" content="halve.png"> <meta name="twitter:title" content="Gradients and Edge Detection"> <meta name="twitter:description" content="Today I look at how I can begin detecting the fingers on my hand using gradient and edge detection techniques"> <meta name="twitter:site" content="@nathangloverAUS"> <meta name="twitter:creator" content="@nathangloverAUS"> <!-- Open Graph --> <meta property="og:locale" content="en_US"> <meta property="og:type" content="article"> <meta property="og:title" content="Gradients and Edge Detection"> <meta property="og:description" content="Today I look at how I can begin detecting the fingers on my hand using gradient and edge detection techniques"> <meta property="og:url" content="https://handmap.github.io/gradients-and-edge-detection/"> <meta property="og:site_name" content="Hand Map"> <meta property="og:image" content="https://handmap.github.io/images/halve.png"> <link rel="canonical" href="https://handmap.github.io/gradients-and-edge-detection/"> <!-- Handheld --> <meta name="HandheldFriendly" content="True"> <meta name="MobileOptimized" content="320"> <meta name="viewport" content="width=device-width, initial-scale=1.0"> <!-- Feed --> <link type="application/atom+xml" rel="alternate" href="https://handmap.github.io/feed.xml" title="Hand Map" /> <!-- Favicons --> <link rel="shortcut icon" type="image/png" href="https://handmap.github.io/favicon.png" /> <link rel="shortcut icon" href="https://handmap.github.io/favicon.ico" /> <!-- CSS --> <link rel="stylesheet" type="text/css" href="https://handmap.github.io/assets/css/main.css"> <!-- Left Block Image for Posts --> <style type="text/css"> #posts.inner-post-page .block-left {background: linear-gradient(rgba(0, 0, 0, 0.5), rgba(0, 0, 0, 0.5)), url(https://handmap.github.io/images/unsplash-gallery-image-3.jpg) no-repeat;background-size: cover;} </style> <!-- Left Block Images for Home and Pages --> <style type="text/css"> #posts .block-left {background: linear-gradient(rgba(0, 0, 0, 0.5), rgba(0, 0, 0, 0.5)), url(https://handmap.github.io/images/unsplash-image-10.jpg) no-repeat;background-size: cover, cover;} .block-left {background: linear-gradient(rgba(44,45,51,0.9), rgba(44,45,51,0.9)), url(https://handmap.github.io/images/home.png) no-repeat;background-size: cover;} </style> </head> <body id="posts" class="inner-post-page"> <div class="block-left"> <div class="content"> <a href="https://handmap.github.io" class="logo"><img src="https://handmap.github.io/images/halve.png"></a> <div class="post-title-section"> <div class="section-line">Posts <em>/</em></div> <h1 class="section-title">Gradients and Edge Detection </h1> <ul class="tags"> <li><a href="https://handmap.github.io/tags#opencv">opencv</a></li> <li><a href="https://handmap.github.io/tags#edge detection">edge detection</a></li> <li><a href="https://handmap.github.io/tags#gradient">gradient</a></li> </ul> <div class="section-line reverse"><a href="https://handmap.github.io/posts">Back to posts</a> <em>/</em></div> </div> </div> </div> <div class="block-right"> <div class="share-buttons"> <a href="https://twitter.com/intent/tweet?text=https://handmap.github.io/gradients-and-edge-detection/" class="btn btn_twitter" title="Share on Twitter"><i class="fa fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a> <a href="https://www.facebook.com/sharer/sharer.php?u=https://handmap.github.io/gradients-and-edge-detection/" class="btn btn_facebook" title="Share on Facebook"><i class="fa fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a> <a href="https://plus.google.com/share?url=https://handmap.github.io/gradients-and-edge-detection/" class="btn btn_google-plus" title="Share on Google Plus"><i class="fa fa-fw fa-google-plus" aria-hidden="true"></i><span> Google+</span></a> </div> <a href="../posts.html" title="posts" class="posts-menu-icon"></a> <a title="projects" class="projects-menu-icon"> <span></span> </a> <div class="inner-post content"> <div class="date-highlight">22 Aug 2016</div> <h2 id="introduction">Introduction</h2> <hr /> <p>Today I decided I’d best start actually writing some code that is vaguely relevant to my original project scope; that is, I’ll be looking at a method for detecting my hand using Gradient and Edge detection. The tutorials I’m following are again from Adrian Rosebrock’s book titled <a href="https://www.pyimagesearch.com/practical-python-opencv/">Practical Python and OpenCV</a>.</p> <p>The process requires me to first find the gradient values of a image that has been converted to grayscale, this allows for each detection of ‘edge-like’ regions which will hopefully be my fingers.</p> <p>We’ll then apply a Canny edge detection and some other blurring techniques to give us a much better chance of detecting the parts of the hand we want to be focusing on.</p> <h2 id="explore-the-code">Explore the Code</h2> <hr /> <p>Below is the final code that we’ll be working towards in this section. It’s briefly commented but I would like to explain exactly what each part does so we have a total understanding of the process.</p> <div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">cv2</span>

<span class="c"># Load the image, convert it to grayscale, and show it</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s">"hand.png"</span><span class="p">)</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s">"Greyscale"</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span>

<span class="c"># Compute the Laplacian of the image</span>
<span class="n">lap</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">Laplacian</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">CV_64F</span><span class="p">)</span>
<span class="n">lap</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">lap</span><span class="p">))</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s">"Laplacian"</span><span class="p">,</span> <span class="n">lap</span><span class="p">)</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">waitKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c"># Compute gradients along the X and Y axis, respectively</span>
<span class="n">sobelX</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">Sobel</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">CV_64F</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">sobelY</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">Sobel</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">CV_64F</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c"># The sobelX and sobelY images are now of the floating</span>
<span class="c"># point data type -- we need to take care when converting</span>
<span class="c"># back to an 8-bit unsigned integer that we do not miss</span>
<span class="c"># any images due to clipping values outside the range</span>
<span class="c"># of [0, 255]. First, we take the absolute value of the</span>
<span class="c"># graident magnitude images, THEN we convert them back</span>
<span class="c"># to 8-bit unsigned integers</span>
<span class="n">sobelX</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">sobelX</span><span class="p">))</span>
<span class="n">sobelY</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">sobelY</span><span class="p">))</span>

<span class="c"># We can combine our Sobel gradient images using our</span>
<span class="c"># bitwise OR</span>
<span class="n">sobelCombined</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">bitwise_or</span><span class="p">(</span><span class="n">sobelX</span><span class="p">,</span> <span class="n">sobelY</span><span class="p">)</span>

<span class="c"># Show our Sobel images</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s">"Sobel X"</span><span class="p">,</span> <span class="n">sobelX</span><span class="p">)</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s">"Sobel Y"</span><span class="p">,</span> <span class="n">sobelY</span><span class="p">)</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s">"Sobel Combined"</span><span class="p">,</span> <span class="n">sobelCombined</span><span class="p">)</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">waitKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div> <h3 id="convert-image-to-grayscale">Convert image to grayscale</h3> <hr /> <p>First part of the code is all the normal imports. In this section we’ll just be using the standard NumPy and OpenCV libraries. The image we’ll be running these test on can be seen below along with the code</p> <figure> <img src="https://handmap.github.io/images/posts/2016-08-22/hand.png" alt="OpenCV Base Hand Image" /> <figcaption>Normal Hand Image</figcaption> </figure> <div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">cv2</span>

<span class="c"># Load the image, convert it to grayscale, and show it</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s">"hand.png"</span><span class="p">)</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s">"Original"</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span>
</code></pre></div> <p>As you can see above, we’ve setup the simple loading of an image and then use the <code class="highlighter-rouge">cvtColor()</code> function to convert the image to greyscale.</p> <blockquote> <p>NOTE: We are able to compute gradients for RGB pictures however for simplicity we’ll be using greyscale until we’ve got a better understanding on how this works</p> </blockquote> <p>Running this code now will produce a greyscale image equivalent to the image we input:</p> <figure> <img src="https://handmap.github.io/images/posts/2016-08-22/greyscale.png" alt="OpenCV Greyscale Image" /> <figcaption>Greyscale Hand Image</figcaption> </figure> <h3 id="laplacian">Laplacian</h3> <hr /> <p>The next step is to apply the Laplacian method to compute the gradient magnitude.</p> <div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># Compute the Laplacian of the image</span>
<span class="n">lap</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">Laplacian</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">CV_64F</span><span class="p">)</span>
<span class="n">lap</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">lap</span><span class="p">))</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s">"Laplacian"</span><span class="p">,</span> <span class="n">lap</span><span class="p">)</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">waitKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div> <p>This is done by calling the <code class="highlighter-rouge">Laplacian()</code> method which takes two inputs:</p> <ol> <li>image : This is our greyscale image</li> <li>data_type : We use a 64bit float due to the negative slope induced by transforming the image from white-to-black. A 64bit float supports the negative numbers we’ll be dealing with when the Laplacian method is run.</li> </ol> <p>The next line takes the absolute value of our Laplacian image transformation and converts the values back to an unsigned 8bit integer suitable for our output. This shows how important it was to initially use the 64bit float as it meant we get a much more accurate result that doesn’t lose any out of bounds values.</p> <p>The output of the Laplacian method can be seen below:</p> <figure> <img src="https://handmap.github.io/images/posts/2016-08-22/laplacian.png" alt="OpenCV Laplacian Image" /> <figcaption>Laplacian Hand Image</figcaption> </figure> <h3 id="sobel-gradient">Sobel Gradient</h3> <p>The other method we’re going to use is called Sobel Gradient representation. The Maths behind this technique will be investigated further if we find the method to be fruitful. For now we’ll just test to see if it does anything useful for our image.</p> <div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># Compute gradients along the X and Y axis, respectively</span>
<span class="n">sobelX</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">Sobel</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">CV_64F</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">sobelY</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">Sobel</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">CV_64F</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">sobelX</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">sobelX</span><span class="p">))</span>
<span class="n">sobelY</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">sobelY</span><span class="p">))</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s">"Sobel X"</span><span class="p">,</span> <span class="n">sobelX</span><span class="p">)</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s">"Sobel Y"</span><span class="p">,</span> <span class="n">sobelY</span><span class="p">)</span>
</code></pre></div> <p>The first two expressions deal with computing the gradients along the X and Y axis respectively. Notice we again use the 64bit floating point data type to ensure we keep our calculation significance. We then retrieve the absolute values of the two calculations and display the results.</p> <figure> <img src="https://handmap.github.io/images/posts/2016-08-22/sobel-x.png" alt="OpenCV Sobel X Image" /> <figcaption>Sobel X Hand Image</figcaption> </figure> <figure> <img src="https://handmap.github.io/images/posts/2016-08-22/sobel-y.png" alt="OpenCV Sobel Y Image" /> <figcaption>Sobel Y Hand Image</figcaption> </figure> <div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">sobelCombined</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">bitwise_or</span><span class="p">(</span><span class="n">sobelX</span><span class="p">,</span> <span class="n">sobelY</span><span class="p">)</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s">"Sobel Combined"</span><span class="p">,</span> <span class="n">sobelCombined</span><span class="p">)</span>
</code></pre></div> <p>Finally we can combine the results of our X and Y images by simply applying a logical bitwise OR to produce a resulting combined Sobel image.</p> <figure> <img src="https://handmap.github.io/images/posts/2016-08-22/sobel-combined.png" alt="OpenCV Sobel Combined Image" /> <figcaption>Sobel Combined Hand Image</figcaption> </figure> <h2 id="canny-edge-detector">Canny Edge Detector</h2> <hr /> <p>While the above resulting image doesn’t look very helpful, it does give us some very defined edges that completely outline the hand. However, we can’t assume it’s going to be our best method so now let’s take a look at Canny Edge detection.</p> <p>I briefly looked at an example of Canny Edge detection in one of my first posts but I never really learnt how to implement it pseudo-myself; so here goes.</p> <div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">cv2</span>

<span class="c"># Load the image, convert it to grayscale, and blur it</span>
<span class="c"># slightly to remove high frequency edges that we aren't</span>
<span class="c"># interested in</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s">"hand.png"</span><span class="p">)</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">GaussianBlur</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s">"Blurred"</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">imwrite</span><span class="p">(</span><span class="s">"blurred.png"</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span>

<span class="c"># When performing Canny edge detection we need two values</span>
<span class="c"># for hysteresis: threshold1 and threshold2. Any gradient</span>
<span class="c"># value larger than threshold2 are considered to be an</span>
<span class="c"># edge. Any value below threshold1 are considered not to</span>
<span class="c"># ben an edge. Values in between threshold1 and threshold2</span>
<span class="c"># are either classified as edges or non-edges based on how</span>
<span class="c"># the intensities are "connected". In this case, any gradient</span>
<span class="c"># values below 30 are considered non-edges whereas any value</span>
<span class="c"># above 150 are considered edges.</span>
<span class="n">canny</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">Canny</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">150</span><span class="p">)</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s">"Canny"</span><span class="p">,</span> <span class="n">canny</span><span class="p">)</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">imwrite</span><span class="p">(</span><span class="s">"canny-img.png"</span><span class="p">,</span> <span class="n">canny</span><span class="p">)</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">waitKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div> <p>Above is the final code we’ll be working towards. Let’s break it down.</p> <h3 id="greyscal-and-gaussian-blur">Greyscal and Gaussian Blur</h3> <hr /> <p>We start by loading in out base <code class="highlighter-rouge">hand.png</code> image and greyscale it.</p> <div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">cv2</span>

<span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s">"hand.png"</span><span class="p">)</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>
</code></pre></div> <p>Now we’ll use the <code class="highlighter-rouge">GaussianBlur()</code> method to help reduce some of the noisy edges in our image. I’ve opted for a 5x5 kernel size. The kernel size defines the size of the sliding square that moves across the image when applying a Blur. The larger the kernel size, the more blur.</p> <div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">GaussianBlur</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s">"Blurred"</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span>
</code></pre></div> <p>Because the hand is a very defined shape and we’re not at all interested in the wrinkles on my aging skin, this blurring method can be very effective. The output image can be seen below after the Gaussian blur was applied.</p> <figure> <img src="https://handmap.github.io/images/posts/2016-08-22/blurred.png" alt="OpenCV Gaussian blur Image" /> <figcaption>Gaussian blur Hand Image</figcaption> </figure> <p>Finally we put the image through the <code class="highlighter-rouge">Canny()</code> OpenCV method and view the output image.</p> <div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">canny</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">Canny</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">150</span><span class="p">)</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s">"Canny"</span><span class="p">,</span> <span class="n">canny</span><span class="p">)</span>
</code></pre></div> <p>Two very important variables above are the 30 and 150. These represent the cut off points of the gradient values that are being assessed. It means that any gradients values below 30 are considered non-edges; whereas values above 150 are considered our edges and will be visible in our final Canny transformed image.</p> <h2 id="differing-blur">Differing Blur</h2> <hr /> <p>To start with lets have a look at what different changing the amount of blur has on the output image. Below are five examples of images with differing blur kernel sizes:</p> <figure> <img src="https://handmap.github.io/images/posts/2016-08-22/canny-img-moving.gif" alt="OpenCV Differing Blur Kernels Image" /> <figcaption>OpenCV Differing Blur Kernels Image</figcaption> </figure> <p>As you can see, while you do cut back on imperfections you also lose accuracy on the hand itself. This is where the Canny cut off points come in.</p> <h2 id="differing-canny-cutoffs">Differing Canny cutoffs</h2> <p>In order to get a reasonable set of values for this test I implemented a simple method of iterating through a set of lower and upper bounds (10-&gt;60 lower : 90-&gt;210 upper) and append the values of the X and Y bounds to the image output each time through. The <code class="highlighter-rouge">putText()</code> method was used to apply the text and a helpful reference for the specific parameters can be found <a href="http://docs.opencv.org/2.4/modules/core/doc/drawing_functions.html#puttext">here</a>.</p> <div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">5</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">90</span><span class="p">,</span> <span class="mi">210</span><span class="p">,</span> <span class="mi">5</span><span class="p">):</span>

        <span class="n">canny</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">Canny</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span><span class="n">canny</span><span class="p">,</span> <span class="s">"x:"</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">+</span><span class="s">" y:"</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">650</span><span class="p">),</span> <span class="n">cv2</span><span class="o">.</span><span class="n">FONT_HERSHEY_SIMPLEX</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">255</span><span class="p">)</span>
        <span class="n">cv2</span><span class="o">.</span><span class="n">imwrite</span><span class="p">(</span><span class="s">"_canny-img-"</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">+</span><span class="s">"-"</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">+</span><span class="s">".png"</span><span class="p">,</span> <span class="n">canny</span><span class="p">)</span>
</code></pre></div> <p>The output of this can be viewed in the animated gif below, or if you would like specific please check out the raw images in my <a href="https://github.com/HandMap/OpenCVTutorials/tree/master/chapter10/_canny-images">project repo</a></p> <figure> <img src="https://handmap.github.io/images/posts/2016-08-22/canny-bound-shift-moving.gif" alt="OpenCV Differing Bounds Kernels Image" /> <figcaption>OpenCV Differing Bounds Kernels Image</figcaption> </figure> <h3 id="conclusion">Conclusion</h3> <hr /> <p>Overall both of these methods were very interesting to explore. I’m certainly learning more towards Canny Edge detection however as it seems like a lot more control is available. However the downside to the extra control is the increased overhead associated with scanning the image and recalculating in hopes of finding a more suitable input.</p> <h3 id="references">References</h3> <hr /> <p>OpenCV API drawing_functions - <a href="http://docs.opencv.org/2.4/modules/core/doc/drawing_functions">http://docs.opencv.org/2.4/modules/core/doc/drawing_functions.html#puttext</a></p> <p>Adrian Rosebrock’s Practical Python on OpenCV - <a href="https://www.pyimagesearch.com/practical-python-opencv/">https://www.pyimagesearch.com/practical-python-opencv/</a></p> <br> <a href="https://twitter.com/intent/tweet?text=https://handmap.github.io/gradients-and-edge-detection/" class="btn btn_twitter" title="Share on Twitter"><i class="fa fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a> <a href="https://www.facebook.com/sharer/sharer.php?u=https://handmap.github.io/gradients-and-edge-detection/" class="btn btn_facebook" title="Share on Facebook"><i class="fa fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a> <a href="https://plus.google.com/share?url=https://handmap.github.io/gradients-and-edge-detection/" class="btn btn_google-plus" title="Share on Google Plus"><i class="fa fa-fw fa-google-plus" aria-hidden="true"></i><span> Google+</span></a> <nav class="pagination"> <a href="https://handmap.github.io/drawing-and-image-processing/" class="pagination_pager" title="Drawing and Image Processing ">previous</a> <a href="https://handmap.github.io/handy-gesture-api/" class="pagination_pager" title="‘Handy’ GestureAPI ">next</a> </nav> </div> </div> <!-- JS --> <script src="https://handmap.github.io/assets/js/main.min.js"></script> <!-- Asynchronous Google Analytics snippet --> <script> (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','//www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-71336829-11', 'auto'); ga('require', 'linkid', 'linkid.js'); ga('send', 'pageview'); </script> <div class="overlay"> <ul class="projects-menu"> <li style="background:url(https://github.com/HandMap/HandMap.github.io/blob/master/images/project.jpg) center center no-repeat;"> <a href="https://handmap.github.io" class="inactive" target="_blank" rel="nofollow external"> <span> Hand Map Project <br><em>in progress</em> </span> </a> </li> </ul> </div> </body> </html>
